# Assignment

## Part 1 (SQL Proficiency)


### Task: Using the provided sample dataset, perform a series of SQL queries to demonstrate data retrieval and manipulation abilities.

#### 1. List the total number of orders for each product, sorted by the number of orders.

``` sql
WITH ords AS (
    SELECT 
        ProductID, 
        COUNT(OrderID) AS order_cnt 
    FROM 
        Orders 
    GROUP BY 
        ProductID
) 
SELECT 
    dm_product.ProductID, 
    dm_product.ProductName, 
    COALESCE(ords.order_cnt, 0) AS order_cnt 
FROM 
    Products 
LEFT JOIN 
    ords ON Products.ProductID = ords.ProductID 
ORDER BY order_cnt DESC
```

* Firstly, created a CTE `ords` to get product wise count of orders and named the column `order_cnt` from *Orders* table which is the `Orders.csv` file.
* In the main query, selected the ProductID, ProductName from Products table and used coalesce in the order_cnt to ensure that if there are no orders for a product (i.e., order_cnt is null), it shows 0 instead of *null*.
* And then LEFT JOINED with ords CTE on ProductID which ensures all records from the Products table are included in the result, even if there is no matching record in the ords CTE.
* At lasts the order_cnt (Order Count) is sorted in descending order.


#### 2. Find the total revenue generated by each user.

```sql
select
    Users.UserID,
    coalesce(sum(ords.Amount),0) as TotalRevenue
from Users 
left join
    Orders ords on Users.UserID = ords.UserID
group by Users.UserID
order by TotalRevenue desc
```
* Selected the UserID from Users table to get all the Users who have or haven't placed any orders.
* Did the sum of Amount to get the total revenue and used coalesce to remove null if the user has not brought any revenue.
* At last grouped on UserID to get overall Revenue with the column name TotalRevenue and sorted on TotalRevenue Column in Descending Order.

#### 3. Display users who have not placed any orders.

```sql
select
    Users.UserID,
    coalesce(sum(ords.Amount),0) as TotalRevenue
from Users 
left join
    Orders ords on Users.UserID = ords.UserID
where TotalRevenue = 0
group by Users.UserID
order by TotalRevenue desc
```

* Used the query from the previous question and added a condition of TotalRevenue=0.
This will show users who have not palced any order.

## Part 2 (Data Pipeline Construction)

### Task: Develop a data pipeline using Python that ingests data from provided CSV files, processes it, and loads it into a structured database.

* Started off with installing and importing important libraries


`pip install pandas sqlalchemy ipywidgets`

```python

import pandas as pd
from sqlalchemy import create_engine
import logging
from ipywidgets import FileUpload
import io
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
```
  

- Created a widget to upload csv file in the notebook. 

```python
upload = FileUpload(accept='.csv', multiple=True)
upload 
```

Below is the screenshot of the result

![alt text](Upload.png)

- Then Created a function to read and Preprocess the File

> In the below code snippet, uploaded data is changed to dataframe  and preprocessing is done by dropping the null value and duplicates.

```python
def read_and_clean_data(uploaded_file, filename):
    try:
        
        # Read data from the uploaded file
        df = pd.read_csv(io.BytesIO(uploaded_file))
        #print(uploaded_file + "\n")
        
        # Handle missing values
        df.dropna(inplace=True)

        # Handle duplicates
        df.drop_duplicates(inplace=True)
        logging.info(f"Data read and cleaned from {filename}")
        
        return df
    except Exception as e:
        print(f"Error Reading/processing file: {e}")
        return None
```

- Created a function `create_database` to setup a conenction with database or creating a new database if its not found

```python
def create_database():
    engine = create_engine('sqlite:///Silq.db')
    logging.info("Database Created and Connected")
    return engine
```


- Processed the uploaded and load it into database in the main function
    
    > - Called the `create_database` function and assigned it a variable named *engine*
    > - Ran a for loop if multiple files are uploaded, this helps in processing all at once.
    > - Inside the loop, called `read_and_clean_data` function for preprocessing the data.
    > - At last the dataframe content is written to a SQL table (table_name) in the database represented by *engine* variable.   



```python 
def main():
    engine = create_database()
    for filename, file in upload.value.items():
        table_name = filename.split('.')[0]  # Assuming table name is the filename without the extension
        df = read_and_clean_data(file['content'], filename)
        if df is not None:
            df.to_sql(table_name, engine, if_exists='replace', index=False)
            logging.info(f"Data loaded into {table_name} table successfully")

if __name__ == "__main__":
    main()
```

## Part 3 (Cohort Analysis Using SQL)

### Task: Perform a cohort analysis on the data using SQL to provide insights into user behavior, focusing on user retention.





